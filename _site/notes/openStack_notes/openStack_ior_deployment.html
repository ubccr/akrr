<!DOCTYPE html>
<html lang="en">


<head>
  <meta charset="utf-8">
  <title>Application Kernel Remote Runner (AKRR) </title>
  <link rel="icon" type="image/x-icon" href="/xdmod-jekyll-theme/assets/images/favicon.ico" />
  <link rel="stylesheet" type="text/css" href="/xdmod-jekyll-theme/assets/css/effervescence.css" />
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-44300156-3');
    ga('send', 'pageview');
  </script>
</head>
<body>
  <div id="page-container">
    <div id="page-header">
      <a href="http://open.xdmod.org"><img src="/xdmod-jekyll-theme/assets/images/xdmod_logo.png" alt="XDMoD" /></a>
      <span class="maintitle">Application Kernel Remote Runner (AKRR) Module 2.1.1</span>
    </div>
    
    <div id="page-body">
      <div class="clear"></div>
      <div id="page-menu">
          <div class="page-menu-toc">
        
            
                <h2>About</h2>
                
                    <ul>
                    
                            
                            <li ><a href="/">Overview</a></li>
                            
                    
                    </ul>
                
            
                <h2>Download</h2>
                
                    <ul>
                    
                            
                            <li ><a href="/AKRR_Download.html">Download</a></li>
                            
                    
                    </ul>
                
            
                <h2>Install</h2>
                
                    <ul>
                    
                            
                            <li ><a href="/AKRR_Install.html">Install</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_Update.html">Update</a></li>
                            
                    
                    </ul>
                
            
                <h2>Using</h2>
                
                    <ul>
                    
                            
                            <li ><a href="/AKRR_Usage.html">Using</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_Add_Resource.html">Adding New Resource</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_Deployment_of_Application_Kernel_on_Resource.html">Adding Appkernel to Resource</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_NAMD_Deployment.html">Adding NAMD</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_HPCC_Deployment.html">Adding HPCC</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_HPCG_Deployment.html">Adding HPCG</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_IMB_Deployment.html">Adding IMB</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_IOR_Deployment.html">Adding IOR</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_MDTest_Deployment.html">Adding MDTest</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_NWChem_Deployment.html">Adding NWChem</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_GAMESS_Deployment.html">Adding GAMESS</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_ENZO_Deployment.html">Adding ENZO</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_Tasks_Scheduling.html">Scheduling Appkernels</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_Walltimelimit_Setting.html">Setting AK Walltime</a></li>
                            
                    
                    </ul>
                
            
                <h2>Details</h2>
                
                    <ul>
                    
                            
                            <li ><a href="/AKRR_HowItWorks.html">How It Works</a></li>
                            
                    
                            
                            <li ><a href="/AKRR_Batch_Job_Script_Generation.html">Batch Job Script Generation</a></li>
                            
                    
                    </ul>
                
            
                <h2>Next</h2>
                
                    <ul>
                    
                            
                            <li ><a href="https://appkernels.xdmod.org/">xdmod-appkernels</a></li>
                            
                    
                    </ul>
                
            
        
    </div>
          
        
      </div>
      <div id="page-content">
         <h1></h1> 
        <h3 id="deployment-of-ior-on-openstack">Deployment of ior on openstack</h3>

<p>Okay so first I’ll try using the ior_barebones02 docker image to try and get it to work on openstack. So</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>akrr app add <span class="nt">-a</span> ior <span class="nt">-r</span> open-lakeeffect-stack

<span class="c">#Output</span>
<span class="o">[</span>INFO] Generating application kernel configuration <span class="k">for </span>ior on open-lakeeffect-stack
<span class="o">[</span>INFO] Application kernel configuration <span class="k">for </span>ior on open-lakeeffect-stack is <span class="k">in</span>: 
        /home/hoffmaps/projects/akrr/etc/resources/open-lakeeffect-stack/ior.app.conf
</code></pre></div></div>
<p>initial config for ior:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># which IO API/formats to check</span>
testPOSIX <span class="o">=</span> True
testMPIIO <span class="o">=</span> False
testHDF5 <span class="o">=</span> False
testNetCDF <span class="o">=</span> False

<span class="c"># will do write test first and after that read, that minimize the caching impact from storage nodes</span>
<span class="c"># require large temporary storage easily 100s GiB</span>
doAllWritesFirst <span class="o">=</span> True

appkernel_run_env_template <span class="o">=</span> <span class="s2">"""
# load application environment
# module load hdf5
module list

# set executable location
EXE=</span><span class="nv">$AKRR_APPKER_DIR</span><span class="s2">/execs/ior/src/ior

# set how to run mpirun on all nodes
for node in </span><span class="nv">$AKRR_NODELIST</span><span class="s2">; do echo </span><span class="nv">$node</span><span class="s2">&gt;&gt;all_nodes; done
RUNMPI="</span>mpiexec <span class="nt">-n</span> <span class="nv">$AKRR_CORES</span> <span class="nt">-f</span> all_nodes<span class="s2">"

# set how to run mpirun on all nodes with offset, first print all nodes after node 1 and then node 1
sed -n "</span><span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="o">+</span><span class="m">1</span><span class="k">))</span>,<span class="k">$((</span><span class="nv">$AKRR_CORES</span><span class="k">))</span>p<span class="s2">" all_nodes &gt; all_nodes_offset
sed -n "</span>1,<span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="k">))</span>p<span class="s2">" all_nodes &gt;&gt; all_nodes_offset
RUNMPI_OFFSET="</span>mpiexec <span class="nt">-n</span> <span class="nv">$AKRR_CORES</span> <span class="nt">-f</span> all_nodes_offset<span class="s2">"
"""</span>
</code></pre></div></div>
<p>Now, from running ior on vortex, this is the config file from that:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>hoffmaps@dhcp-128-205-70-4 open-lakeeffect-stack]<span class="nv">$ </span><span class="nb">cat</span> ../vortex_dock_sing/ior.app.conf 
<span class="c"># which IO API/formats to check</span>
testPOSIX <span class="o">=</span> True
testMPIIO <span class="o">=</span> False
testHDF5 <span class="o">=</span> False
testNetCDF <span class="o">=</span> False

<span class="c"># will do write test first and after that read, that minimize the caching impact from storage nodes</span>
<span class="c"># require large temporary storage easily 100s GiB</span>
doAllWritesFirst <span class="o">=</span> True

appkernel_run_env_template <span class="o">=</span> <span class="s2">"""
# load application environment
# module load hdf5
module load intel
module load intel-mpi
module list

# set executable location
EXE="</span>/gpfs/scratch/hoffmaps/singularity_images/akrr_benchmarks_ior_barebones02.sif<span class="s2">"

 #set how to run mpirun on all nodes
export LD_LIBRARY_PATH=/opt/appker/lib:/opt/intel/impi/2018.3.222/lib64:</span><span class="nv">$LD_LIBRARY_PATH</span><span class="s2">
unset TMPDIR
</span><span class="nv">$EXE</span><span class="s2"> --appsigcheck &gt;&gt; </span><span class="nv">$AKRR_APP_STDOUT_FILE</span><span class="s2"> 2&gt;&amp;1
EXE="</span><span class="nv">$EXE</span> <span class="nt">--ior-run</span><span class="s2">"
for node in </span><span class="nv">$AKRR_NODELIST</span><span class="s2">; do echo </span><span class="nv">$node</span><span class="s2">&gt;&gt;all_nodes; done
RUNMPI="</span>mpiexec <span class="nt">-n</span> <span class="nv">$AKRR_CORES</span> <span class="nt">-f</span> all_nodes<span class="s2">"

# set how to run mpirun on all nodes with offset, first print all nodes after node 1 and then node 1
sed -n "</span><span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="o">+</span><span class="m">1</span><span class="k">))</span>,<span class="k">$((</span><span class="nv">$AKRR_CORES</span><span class="k">))</span>p<span class="s2">" all_nodes &gt; all_nodes_offset
sed -n "</span>1,<span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="k">))</span>p<span class="s2">" all_nodes &gt;&gt; all_nodes_offset
RUNMPI_OFFSET="</span>mpiexec <span class="nt">-n</span> <span class="nv">$AKRR_CORES</span> <span class="nt">-f</span> all_nodes_offset<span class="s2">"
"""</span>
</code></pre></div></div>
<p>So, here is the issue: this calls an executable, but with docker we have to use the run command. So I’ll make a new docker image that runs ior inside docker with the mpi exec and such, aka sorta doing what is being done in the ior.job stuff.</p>

<p>UPDATE ran into that pesky json error again - cannot hand out too many tokens or whatever, so it looks like the whole revoke token thing didn’t really work</p>

<p>So I had some errors with the filesystem…. somehow with docker the directories or something couldn’t be found…? Not exactly sure what was going on, but at the very least I got things working on openstack. The configuration of ior.app.conf is below along with the explanation</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>hoffmaps@dhcp-128-205-70-4 open-lakeeffect-stack]<span class="nv">$ </span><span class="nb">cat </span>ior.app.conf 
<span class="c"># which IO API/formats to check</span>
testPOSIX <span class="o">=</span> True
testMPIIO <span class="o">=</span> False
testHDF5 <span class="o">=</span> False
testNetCDF <span class="o">=</span> False

<span class="c"># setting false up here so we can just run on one node</span>
appkernel_requests_two_nodes_for_one <span class="o">=</span> False

<span class="c"># will do write test first and after that read, that minimize the caching impact from storage nodes</span>
<span class="c"># require large temporary storage easily 100s GiB</span>
doAllWritesFirst <span class="o">=</span> True

appkernel_run_env_template <span class="o">=</span> <span class="s2">"""
sudo systemctl start docker
docker pull pshoff/akrr_benchmarks:ior_docker
EXE="</span>docker run <span class="nt">-v</span> <span class="nv">$AKRR_TMP_WORKDIR</span>:<span class="nv">$AKRR_TMP_WORKDIR</span> <span class="nt">--rm</span> pshoff/akrr_benchmarks:ior_docker<span class="s2">"

# set how to run mpirun on all nodes
for node in </span><span class="nv">$AKRR_NODELIST</span><span class="s2">; do echo </span><span class="nv">$node</span><span class="s2">&gt;&gt;all_nodes; done
# putting nothing here bc further down we don't want to use it really
RUNMPI=""

# set how to run mpirun on all nodes with offset, first print all nodes after node 1 and then node 1
sed -n "</span><span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="o">+</span><span class="m">1</span><span class="k">))</span>,<span class="k">$((</span><span class="nv">$AKRR_CORES</span><span class="k">))</span>p<span class="s2">" all_nodes &gt; all_nodes_offset
sed -n "</span>1,<span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="k">))</span>p<span class="s2">" all_nodes &gt;&gt; all_nodes_offset
# same for this run
RUNMPI_OFFSET=""
"""</span>
</code></pre></div></div>
<ul>
  <li>Deleted the stuff at the Runmpi bc that is being done in the docker container</li>
  <li>The EXE is just the docker run, then all the arguments get passed through to the run script, which does mpiexec.</li>
  <li>set the appkernel_requests_two_nodes_for_one to False, since we’re treating openstack as only being one node</li>
  <li>This does mean that the whole offset thing is useless…</li>
  <li>also like the results are sorta weird bc its saying we can write 20 gb per second and that’s a LOT</li>
</ul>

<p>The final configuration file, after adding in the appsigcheck:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># which IO API/formats to check</span>
testPOSIX <span class="o">=</span> True
testMPIIO <span class="o">=</span> False
testHDF5 <span class="o">=</span> False
testNetCDF <span class="o">=</span> False

<span class="c"># setting false up here so we can just run on one node</span>
appkernel_requests_two_nodes_for_one <span class="o">=</span> False

<span class="c"># will do write test first and after that read, that minimize the caching impact from storage nodes</span>
<span class="c"># require large temporary storage easily 100s GiB</span>
doAllWritesFirst <span class="o">=</span> True

appkernel_run_env_template <span class="o">=</span> <span class="s2">"""
sudo systemctl start docker
docker pull pshoff/akrr_benchmarks:ior
EXE="</span>docker run <span class="nt">-v</span> <span class="nv">$AKRR_TMP_WORKDIR</span>:<span class="nv">$AKRR_TMP_WORKDIR</span> <span class="nt">--rm</span> pshoff/akrr_benchmarks:ior <span class="nt">--ior-run</span> <span class="nt">--proc</span> 8<span class="s2">"
^^
# sending over how many processes we want to run (see docker directory for more)

# to get appsig
docker run --rm pshoff/akrr_benchmarks:ior --appsigcheck &gt;&gt; </span><span class="nv">$AKRR_APP_STDOUT_FILE</span><span class="s2"> 2&gt;&amp;1

# set how to run mpirun on all nodes
for node in </span><span class="nv">$AKRR_NODELIST</span><span class="s2">; do echo </span><span class="nv">$node</span><span class="s2">&gt;&gt;all_nodes; done
# putting nothing here bc further down we don't want to use it really
RUNMPI=""

# set how to run mpirun on all nodes with offset, first print all nodes after node 1 and then node 1
sed -n "</span><span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="o">+</span><span class="m">1</span><span class="k">))</span>,<span class="k">$((</span><span class="nv">$AKRR_CORES</span><span class="k">))</span>p<span class="s2">" all_nodes &gt; all_nodes_offset
sed -n "</span>1,<span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="k">))</span>p<span class="s2">" all_nodes &gt;&gt; all_nodes_offset
# same for this run
RUNMPI_OFFSET=""
"""</span>
</code></pre></div></div>

<p>After adjusting some things to have ior and mdtest working with the same docker image, this is the final config</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># which IO API/formats to check</span>
testPOSIX <span class="o">=</span> True
testMPIIO <span class="o">=</span> False
testHDF5 <span class="o">=</span> False
testNetCDF <span class="o">=</span> False

<span class="c"># setting false up here so we can just run on one node</span>
appkernel_requests_two_nodes_for_one <span class="o">=</span> False

<span class="c"># will do write test first and after that read, that minimize the caching impact from storage nodes</span>
<span class="c"># require large temporary storage easily 100s GiB</span>
doAllWritesFirst <span class="o">=</span> True

appkernel_run_env_template <span class="o">=</span> <span class="s2">"""
sudo systemctl start docker
docker pull pshoff/akrr_benchmarks:ior_mdtest
EXE="</span>docker run <span class="nt">-v</span> <span class="nv">$AKRR_TMP_WORKDIR</span>:<span class="nv">$AKRR_TMP_WORKDIR</span> <span class="nt">--rm</span> pshoff/akrr_benchmarks:ior_mdtest <span class="nt">--run-ior</span> <span class="nt">--proc</span> 8<span class="s2">"

# to get appsig
docker run --rm pshoff/akrr_benchmarks:ior_mdtest --appsig-ior &gt;&gt; </span><span class="nv">$AKRR_APP_STDOUT_FILE</span><span class="s2"> 2&gt;&amp;1

# set how to run mpirun on all nodes
for node in </span><span class="nv">$AKRR_NODELIST</span><span class="s2">; do echo </span><span class="nv">$node</span><span class="s2">&gt;&gt;all_nodes; done
# putting nothing here bc further down we don't want to use it really
RUNMPI=""

# set how to run mpirun on all nodes with offset, first print all nodes after node 1 and then node 1
sed -n "</span><span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="o">+</span><span class="m">1</span><span class="k">))</span>,<span class="k">$((</span><span class="nv">$AKRR_CORES</span><span class="k">))</span>p<span class="s2">" all_nodes &gt; all_nodes_offset
sed -n "</span>1,<span class="k">$((</span><span class="nv">$AKRR_CORES_PER_NODE</span><span class="k">))</span>p<span class="s2">" all_nodes &gt;&gt; all_nodes_offset
# same for this run
RUNMPI_OFFSET=""
"""</span>


</code></pre></div></div>


      </div>
      <div class="clear"></div>
    </div>
    <div id="page-footer">
      <a href="https://www.buffalo.edu/ccr" target="_blank"><img src="/xdmod-jekyll-theme/assets/images/ccr_logo.png" alt="Center for Computational Research"/></a>
    </div>
  </div>
</body>
</html>
